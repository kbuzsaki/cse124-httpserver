# Experimental Results for Extension 3

Kyle Buzsaki
A11462453


## Methodology

I used the following commands for benchmarking:

    ab -n 1000 -c $conc -H 'Connection: close' localhost:6060/foo.html
    ab -n 200 -c $conc -H 'Connection: close' localhost:6060/ten_meg.png

Where $conc is the concurrency level of 2, 3, 4, 5, 10, or 20. The foo.html 
file is 37 bytes in size. The ten_meg.png file is 10 megabytes in size.

The servers were run with the following commands:

    ./httpd 6060 itest_files nopool
    ./httpd 6060 itest_files pool 5

The output of the ab command can be found in the results directory.


## Results

See the result files in the results directory of the repository.
See the aggregated and charted results in this google spreadsheet:
https://docs.google.com/spreadsheets/d/1QV3yLazswKzvgaDeHi7DN3E0Itsd8MGcl97Fj5_uHNQ/edit?usp=sharing
Or saved to the results_analysis directory


Q1. Does the latency of a small request vary between the two threading models
for pools of size 5 when evaluated at concurrency levels of {2,3,4,5}?

A: The median response times for both models are 2, 3, 4, and 5 milliseconds
respectively. However, the 99th percentile response times for the nopool model
are generally a few milliseconds higher than the 99th percentile reponse times
for the pool model. This makes sense to me because nopool model has to make
an additional system call to spawn the thread that could cause additional delays.
Furthermore, the pooled model has a smaller standard deviation than the
no pool model. This makes sense for the same reason.


Q2. Does the throughput of large requests vary between the two threading models
for pools of size 5 when evalutaed at concurrency levels of {2,3,4,5}?

A: No, large request throughput is almost identical between the two threading models
for concurrency levels of 2, 3, 4, and 5. This makes sense because with large responses,
unlike small responses, the majority of the time is spent in IO wait. This means that
even if spawning a thread per connection has additional cost, it is outweighed by the
cost of actually servicing the connection.


Q3. Does the latency of a small request vary between the two threading models
for pools of size 5 when evaluated at concurrency levels of {10,20}?

A: Again, the pooled model beats the nopool model in terms of 99th percentile times
and standard deviation. This makes sense for the same reason: the thread-per-connection
model has to do additional work to create new threads that may cause unexpected delays.
The median times are again similar. At concurrency 20 seconds the standard deviation
difference is about 2 milliseconds and the 50th percentile and 99th percentile processing
times are lower by about 1 millisecond.


Q4. Does the throughput of large requests vary between the two threading models
for pools of size 5 when evalutaed at concurrency levels of {10,20}?

A: Performance of the pooled model drops by about 1% at concurrency 10 and by 2.5%
at concurrency 20 for both requests per second and transfer rate. The effect isn't
massive, but this makes sense because again the majority of time processing the
connections is spent in IO wait, so a thread-per-connection model is able to have
more threads in IO wait at a time than a thread pool model. The thread pool model's
advantage of having threads ready to go more quickly is again outweighed, and the
large number of threads do not contend for CPU much because they are spending so much
of their time in IO wait.
